{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNZ9JaswkH2j3xmxXhjrTQN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aravind8281/Natural_language_Processing/blob/main/GenSim.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hLUfTbZY_ws1",
        "outputId": "65691314-0512-40f6-8a32-ba77d9ec238c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.11.4)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (6.4.0)\n"
          ]
        }
      ],
      "source": [
        "pip install gensim\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Vector space model"
      ],
      "metadata": {
        "id": "zeTSkt5pEbRG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim import corpora\n",
        "from gensim.models import TfidfModel\n",
        "corpus = [\n",
        "    \"Gensim is an open-source library for topic modeling.\",\n",
        "    \"Vector space models are essential in natural language processing.\",\n",
        "    \"The TfidfModel in Gensim calculates the term-document matrix.\",\n",
        "    \"Inverse document frequency (IDF) is crucial for information retrieval.\",\n",
        "]\n",
        "\n",
        "\n",
        "tokenized_corpus=[doc.split() for doc in corpus]\n",
        "print(tokenized_corpus)\n",
        "dictionary=corpora.Dictionary(tokenized_corpus)\n",
        "print(\"Dictionary :\",dictionary)\n",
        "term_document=[dictionary.doc2bow(doc) for doc in tokenized_corpus]\n",
        "tfid_model=TfidfModel(term_document)\n",
        "tfid_matrix=tfid_model[term_document]\n",
        "print(\"Term-Document Matrix:\")\n",
        "for doc in tfidf_matrix:\n",
        "    print(doc)\n",
        "print(\"\\nInverse Document Frequency (IDF):\")\n",
        "for term, idf_value in tfidf_model.idfs.items():\n",
        "    print(f\"{dictionary[term]}: {idf_value}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYl2D-Lp_zfI",
        "outputId": "5406687f-8fb3-4594-bcb8-8aec67a3f9a8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['Gensim', 'is', 'an', 'open-source', 'library', 'for', 'topic', 'modeling.'], ['Vector', 'space', 'models', 'are', 'essential', 'in', 'natural', 'language', 'processing.'], ['The', 'TfidfModel', 'in', 'Gensim', 'calculates', 'the', 'term-document', 'matrix.'], ['Inverse', 'document', 'frequency', '(IDF)', 'is', 'crucial', 'for', 'information', 'retrieval.']]\n",
            "Dictionary : Dictionary<30 unique tokens: ['Gensim', 'an', 'for', 'is', 'library']...>\n",
            "Term-Document Matrix:\n",
            "[(0, 0.20851441405707477), (1, 0.41702882811414954), (2, 0.20851441405707477), (3, 0.20851441405707477), (4, 0.41702882811414954), (5, 0.41702882811414954), (6, 0.41702882811414954), (7, 0.41702882811414954)]\n",
            "[(8, 0.3481553119113957), (9, 0.3481553119113957), (10, 0.3481553119113957), (11, 0.17407765595569785), (12, 0.3481553119113957), (13, 0.3481553119113957), (14, 0.3481553119113957), (15, 0.3481553119113957), (16, 0.3481553119113957)]\n",
            "[(0, 0.19611613513818404), (11, 0.19611613513818404), (17, 0.3922322702763681), (18, 0.3922322702763681), (19, 0.3922322702763681), (20, 0.3922322702763681), (21, 0.3922322702763681), (22, 0.3922322702763681)]\n",
            "[(2, 0.18257418583505536), (3, 0.18257418583505536), (23, 0.3651483716701107), (24, 0.3651483716701107), (25, 0.3651483716701107), (26, 0.3651483716701107), (27, 0.3651483716701107), (28, 0.3651483716701107), (29, 0.3651483716701107)]\n",
            "\n",
            "Inverse Document Frequency (IDF):\n",
            "Gensim: 1.0\n",
            "an: 2.0\n",
            "for: 1.0\n",
            "is: 1.0\n",
            "library: 2.0\n",
            "modeling.: 2.0\n",
            "open-source: 2.0\n",
            "topic: 2.0\n",
            "Vector: 2.0\n",
            "are: 2.0\n",
            "essential: 2.0\n",
            "in: 1.0\n",
            "language: 2.0\n",
            "models: 2.0\n",
            "natural: 2.0\n",
            "processing.: 2.0\n",
            "space: 2.0\n",
            "TfidfModel: 2.0\n",
            "The: 2.0\n",
            "calculates: 2.0\n",
            "matrix.: 2.0\n",
            "term-document: 2.0\n",
            "the: 2.0\n",
            "(IDF): 2.0\n",
            "Inverse: 2.0\n",
            "crucial: 2.0\n",
            "document: 2.0\n",
            "frequency: 2.0\n",
            "information: 2.0\n",
            "retrieval.: 2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Latent Semantic Analysis"
      ],
      "metadata": {
        "id": "Lp2TLA9_FU00"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim import corpora\n",
        "from gensim.models import TfidfModel\n",
        "from gensim.models import LsiModel\n",
        "from pprint import pprint\n",
        "documents = [\n",
        "    \"Gensim is a Python library for topic modeling and document similarity analysis.\",\n",
        "    \"Latent Semantic Analysis (LSA) is a technique used for extracting hidden semantic structures in a document collection.\",\n",
        "    \"The Vector Space Model (VSM) is fundamental for tasks like document similarity and topic modeling.\",\n",
        "]\n",
        "\n",
        "tokenized_corpus=[doc.lower().split() for doc in documents]\n",
        "dictionary=corpora.Dictionary(tokenized_corpus)\n",
        "corpus=[dictionary.doc2bow(doc) for doc in tokenized_corpus]\n",
        "tfidf_model = TfidfModel(corpus)\n",
        "tfidf_corpus = tfidf_model[corpus]\n",
        "num_topics = 2\n",
        "lsa_model = LsiModel(tfidf_corpus, num_topics=num_topics)\n",
        "pprint(lsa_model.print_topics())\n",
        "term_document_matrix = lsa_model[tfidf_corpus]\n",
        "for doc, as_text in zip(term_document_matrix, tokenized_docs):\n",
        "    print(as_text)\n",
        "    print(doc)\n",
        "    print()\n",
        "idf = tfidf_model.idfs\n",
        "print(\"Inverse Document Frequency (IDF):\")\n",
        "for term, value in zip(dictionary.token2id.keys(), idf):\n",
        "    print(f\"{term}: {value}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kx5cg7FM_7AS",
        "outputId": "5c32cfa1-6a4d-42a1-eff2-8e0d4292fd8a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.lsimodel:no word id mapping provided; initializing from corpus, assuming identity\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(0,\n",
            "  '0.291*\"1\" + 0.291*\"5\" + 0.291*\"8\" + 0.291*\"7\" + 0.291*\"9\" + 0.197*\"24\" + '\n",
            "  '0.197*\"27\" + 0.197*\"23\" + 0.197*\"25\" + 0.197*\"26\"'),\n",
            " (1,\n",
            "  '0.462*\"19\" + 0.231*\"18\" + 0.231*\"14\" + 0.231*\"17\" + 0.231*\"12\" + 0.231*\"22\" '\n",
            "  '+ 0.231*\"21\" + 0.231*\"20\" + 0.231*\"13\" + 0.231*\"16\"')]\n",
            "['gensim', 'is', 'a', 'python', 'library', 'for', 'topic', 'modeling', 'and', 'document', 'similarity', 'analysis.']\n",
            "[(0, 0.7294502910023443)]\n",
            "\n",
            "['latent', 'semantic', 'analysis', '(lsa)', 'is', 'a', 'technique', 'used', 'for', 'extracting', 'hidden', 'semantic', 'structures', 'in', 'a', 'document', 'collection.']\n",
            "[(0, 0.3446988960651882), (1, 0.8813059489870925)]\n",
            "\n",
            "['the', 'vector', 'space', 'model', '(vsm)', 'is', 'fundamental', 'for', 'tasks', 'like', 'document', 'similarity', 'and', 'topic', 'modeling.']\n",
            "[(0, 0.6428688809507336), (1, -0.47254610809947484)]\n",
            "\n",
            "Inverse Document Frequency (IDF):\n",
            "a: 0\n",
            "analysis.: 1\n",
            "and: 2\n",
            "document: 3\n",
            "for: 4\n",
            "gensim: 5\n",
            "is: 6\n",
            "library: 7\n",
            "modeling: 8\n",
            "python: 9\n",
            "similarity: 10\n",
            "topic: 11\n",
            "(lsa): 12\n",
            "analysis: 13\n",
            "collection.: 14\n",
            "extracting: 15\n",
            "hidden: 16\n",
            "in: 17\n",
            "latent: 18\n",
            "semantic: 19\n",
            "structures: 20\n",
            "technique: 21\n",
            "used: 22\n",
            "(vsm): 23\n",
            "fundamental: 24\n",
            "like: 25\n",
            "model: 26\n",
            "modeling.: 27\n",
            "space: 28\n",
            "tasks: 29\n",
            "the: 30\n",
            "vector: 31\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Latent Dirichlet Allocation"
      ],
      "metadata": {
        "id": "IAI5fbCpGygG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim import corpora\n",
        "from gensim.models import LdaModel\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "import string\n",
        "documents = [\n",
        "    \"Topic modeling is an interesting area of natural language processing.\",\n",
        "    \"Latent Dirichlet Allocation is a popular technique for topic modeling.\",\n",
        "    \"Gensim provides an implementation of Latent Dirichlet Allocation.\",\n",
        "    \"The Python programming language is commonly used in data science.\",\n",
        "    \"Stopwords are common words that are often removed in text processing.\",\n",
        "]\n",
        "stop_words = set(stopwords.words('english'))\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "def preprocess_text(text):\n",
        "    tokens = word_tokenize(text.lower())\n",
        "    tokens = [stemmer.stem(token) for token in tokens if token.isalnum() and token not in stop_words]\n",
        "    return tokens\n",
        "processed_documents = [preprocess_text(doc) for doc in documents]\n",
        "dictionary = corpora.Dictionary(processed_documents)\n",
        "corpus = [dictionary.doc2bow(doc) for doc in processed_documents]\n",
        "lda_model = LdaModel(corpus, num_topics=2, id2word=dictionary, passes=10)\n",
        "topics = lda_model.print_topics(num_words=5)\n",
        "for topic in topics:\n",
        "    print(topic)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hWffIZ3vFXmr",
        "outputId": "aaf5d57d-9b2f-4663-e417-a96f7e003bba"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(0, '0.056*\"process\" + 0.056*\"languag\" + 0.054*\"stopword\" + 0.054*\"common\" + 0.054*\"word\"')\n",
            "(1, '0.075*\"dirichlet\" + 0.075*\"latent\" + 0.075*\"alloc\" + 0.075*\"model\" + 0.075*\"topic\"')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Word2vec"
      ],
      "metadata": {
        "id": "-5HDLnZ2Hptn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "sentences = [\n",
        "    \"Word embeddings are powerful tools in NLP.\",\n",
        "    \"They capture semantic relationships between words.\",\n",
        "    \"Word2Vec is a popular technique for creating word embeddings.\"\n",
        "]\n",
        "tokenized_sentences = [word_tokenize(sentence.lower()) for sentence in sentences]\n",
        "model = Word2Vec(sentences=tokenized_sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
        "vector = model.wv['word']\n",
        "similar_words = model.wv.most_similar('word', topn=3)\n",
        "print(\"Vector for 'word':\", vector)\n",
        "print(\"Similar words to 'word':\", similar_words)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXfwBB0vG5Rn",
        "outputId": "2563259b-d839-4e24-f4cf-1ec13463c713"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vector for 'word': [-8.6196875e-03  3.6657380e-03  5.1898835e-03  5.7419385e-03\n",
            "  7.4669183e-03 -6.1676754e-03  1.1056137e-03  6.0472824e-03\n",
            " -2.8400505e-03 -6.1735227e-03 -4.1022300e-04 -8.3689485e-03\n",
            " -5.6000124e-03  7.1045388e-03  3.3525396e-03  7.2256695e-03\n",
            "  6.8002474e-03  7.5307419e-03 -3.7891543e-03 -5.6180597e-04\n",
            "  2.3483764e-03 -4.5190323e-03  8.3887316e-03 -9.8581640e-03\n",
            "  6.7646410e-03  2.9144168e-03 -4.9328315e-03  4.3981876e-03\n",
            " -1.7395747e-03  6.7113843e-03  9.9648498e-03 -4.3624435e-03\n",
            " -5.9933780e-04 -5.6956373e-03  3.8508223e-03  2.7866268e-03\n",
            "  6.8910765e-03  6.1010956e-03  9.5384968e-03  9.2734173e-03\n",
            "  7.8980681e-03 -6.9895042e-03 -9.1558648e-03 -3.5575271e-04\n",
            " -3.0998408e-03  7.8943167e-03  5.9385742e-03 -1.5456629e-03\n",
            "  1.5109634e-03  1.7900408e-03  7.8175711e-03 -9.5101865e-03\n",
            " -2.0553112e-04  3.4691966e-03 -9.3897223e-04  8.3817719e-03\n",
            "  9.0107834e-03  6.5365066e-03 -7.1162102e-04  7.7104042e-03\n",
            " -8.5343346e-03  3.2071066e-03 -4.6379971e-03 -5.0889552e-03\n",
            "  3.5896183e-03  5.3703394e-03  7.7695143e-03 -5.7665063e-03\n",
            "  7.4333609e-03  6.6254963e-03 -3.7098003e-03 -8.7456414e-03\n",
            "  5.4374672e-03  6.5097557e-03 -7.8755023e-04 -6.7098560e-03\n",
            " -7.0859254e-03 -2.4970602e-03  5.1432536e-03 -3.6652375e-03\n",
            " -9.3700597e-03  3.8267397e-03  4.8844791e-03 -6.4285635e-03\n",
            "  1.2085581e-03 -2.0748770e-03  2.4403334e-05 -9.8835090e-03\n",
            "  2.6920044e-03 -4.7501065e-03  1.0876465e-03 -1.5762246e-03\n",
            "  2.1966731e-03 -7.8815762e-03 -2.7171839e-03  2.6631986e-03\n",
            "  5.3466819e-03 -2.3915148e-03 -9.5100943e-03  4.5058788e-03]\n",
            "Similar words to 'word': [('words', 0.16072534024715424), ('popular', 0.15920041501522064), ('between', 0.13725273311138153)]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Doc2Vec"
      ],
      "metadata": {
        "id": "eHysf8jjHth-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Doc2Vec\n",
        "from gensim.models.doc2vec import TaggedDocument\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "documents = [\n",
        "    \"Doc2Vec is an extension of Word2Vec.\",\n",
        "    \"It represents entire documents as vectors.\",\n",
        "    \"Doc2Vec is used for document similarity and categorization.\"\n",
        "]\n",
        "tagged_data = [TaggedDocument(words=word_tokenize(doc.lower()), tags=[str(i)]) for i, doc in enumerate(documents)]\n",
        "model = Doc2Vec(vector_size=100, window=5, min_count=1, workers=4, epochs=100)\n",
        "model.build_vocab(tagged_data)\n",
        "model.train(tagged_data, total_examples=model.corpus_count, epochs=model.epochs)\n",
        "vector = model.dv['0']\n",
        "similar_documents = model.dv.most_similar('0', topn=2)\n",
        "print(\"Vector for document 0:\", vector)\n",
        "print(\"Similar documents to document 0:\", similar_documents)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLIVG8VjHvah",
        "outputId": "fb8ec226-5f50-496e-9abc-7c4025c9d1d4"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vector for document 0: [-7.9716919e-03 -8.3736442e-03 -1.0944714e-02  9.9241920e-03\n",
            "  4.5422944e-03 -5.4450217e-04 -1.0094763e-02 -5.2044634e-03\n",
            " -1.0782715e-02  2.9547068e-03  2.1002844e-03  5.0075110e-03\n",
            " -6.5667988e-03 -4.4701481e-03 -2.2102748e-03 -9.9799922e-03\n",
            "  1.1813106e-03  1.0580492e-02 -1.0827275e-02 -4.1885907e-03\n",
            " -4.3763341e-03  2.8289685e-03 -5.8091190e-03  4.9553094e-03\n",
            "  5.1590684e-03 -8.7494971e-03 -1.0693724e-02 -1.1138376e-02\n",
            "  4.8447046e-03 -1.0996391e-02  6.8827504e-03  6.9135614e-03\n",
            " -6.2759575e-03 -6.1971759e-03 -2.4070984e-03  2.4437967e-03\n",
            " -2.3207248e-03 -1.0111362e-02 -5.1758345e-03  3.7550332e-04\n",
            " -1.5949557e-04 -7.6236208e-03  5.5744550e-03 -1.0257954e-02\n",
            "  2.5768082e-03 -5.1730750e-03  2.6390146e-04 -5.9319602e-04\n",
            "  5.8112508e-03 -1.0814729e-02 -4.2317528e-03 -4.0683089e-04\n",
            " -7.5302068e-03 -8.7972917e-03 -3.1240392e-03  1.1477897e-02\n",
            " -6.2208658e-04  5.0746379e-03 -7.2606523e-03  1.0341367e-02\n",
            "  5.0619435e-03  1.2346759e-02  7.1806652e-03 -5.0291573e-03\n",
            "  2.4660025e-03 -4.6719601e-03  7.0612705e-03  3.3426734e-03\n",
            " -3.0726912e-03 -6.3213287e-03 -1.0036264e-02 -8.9750109e-05\n",
            " -9.9813016e-03 -9.5311506e-03 -7.1997959e-03  2.7772412e-03\n",
            " -7.3984116e-03 -9.6676359e-03  1.4080440e-03  1.2688803e-03\n",
            "  9.3658548e-03  6.1650313e-03 -1.1690979e-02 -6.7935867e-04\n",
            "  7.2804173e-03  4.9956688e-03  3.2428706e-03 -6.1872122e-03\n",
            "  7.2131045e-03  2.5301676e-03 -1.0104703e-02  8.4886756e-03\n",
            " -1.1675359e-02 -8.4965238e-03 -4.4806688e-03  1.3151584e-02\n",
            "  3.8771324e-03 -3.2398279e-03  1.1933714e-02  2.7706679e-03]\n",
            "Similar documents to document 0: [('1', 0.36324018239974976), ('2', 0.2573549151420593)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OOCBQfUdIwFj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}