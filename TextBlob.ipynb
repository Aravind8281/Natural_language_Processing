{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN4U2p440kPpcZlKmj4w3xa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aravind8281/Natural_language_Processing/blob/main/TextBlob.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCuH_mf72Boz",
        "outputId": "2ce5ee9b-2b1e-46b4-db80-b1bc48142ca3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: textblob in /usr/local/lib/python3.10/dist-packages (0.17.1)\n",
            "Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.10/dist-packages (from textblob) (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (4.66.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install textblob"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating textblob"
      ],
      "metadata": {
        "id": "aQ5NkaCH3A0y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob\n",
        "words=\"This is Natural language processing work flow\"\n",
        "blob=TextBlob(words)\n",
        "print(blob)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rq7cmZGq2u4z",
        "outputId": "db65894c-2c94-4816-cca6-39fcdf85ca80"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is Natural language processing work flow\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TextBlob"
      ],
      "metadata": {
        "id": "hEOZPiVs3X5R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('brown')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('punkt')\n",
        "noun=blob.noun_phrases\n",
        "pos=blob.pos_tags\n",
        "words=blob.words\n",
        "sentence=blob.sentences\n",
        "sentiment=blob.sentiment\n",
        "assessment=blob.sentiment_assessments\n",
        "print(\"Noun :\",noun)\n",
        "print(\"Parts of speech :\",pos)\n",
        "print(\"Words :\",words)\n",
        "print(\"Sentence :\",sentence)\n",
        "print(\"Sentiment :\",sentiment)\n",
        "print(\"assessment :\",assessment)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kb1nQd4720K7",
        "outputId": "91d06a48-0c44-41dc-e2c4-44d3438b4a6f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Noun : ['natural language processing work flow']\n",
            "Parts of speech : [('This', 'DT'), ('is', 'VBZ'), ('Natural', 'JJ'), ('language', 'NN'), ('processing', 'NN'), ('work', 'NN'), ('flow', 'NN')]\n",
            "Words : ['This', 'is', 'Natural', 'language', 'processing', 'work', 'flow']\n",
            "Sentence : [Sentence(\"This is Natural language processing work flow\")]\n",
            "Sentiment : Sentiment(polarity=0.1, subjectivity=0.4)\n",
            "assessment : Sentiment(polarity=0.1, subjectivity=0.4, assessments=[(['natural'], 0.1, 0.4, None)])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Package brown is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Spell Checking"
      ],
      "metadata": {
        "id": "TA1AM0Cc5ZCK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word=\"this is natural language processing\"\n",
        "blob=TextBlob(word)\n",
        "spell=blob.correct\n",
        "print(spell)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wy5x9VbP31SN",
        "outputId": "a3f07935-0b86-490c-8c8c-52a4c277a73a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<bound method BaseBlob.correct of TextBlob(\"this is natural language processing\")>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# N-grams"
      ],
      "metadata": {
        "id": "hdCwP1YA60_z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word=\"this is natural language processing\"\n",
        "blob=TextBlob(word)\n",
        "ngram=blob.ngrams\n",
        "print(ngram)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_T6_A_Tv55ao",
        "outputId": "9e2b73fb-f810-4855-9d96-1bac8cfad360"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<bound method BaseBlob.ngrams of TextBlob(\"this is natural language processing\")>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Naive Bayes Classifier"
      ],
      "metadata": {
        "id": "QjLuxLjV9KFA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob.classifiers import NaiveBayesClassifier\n",
        "\n",
        "train_data = [\n",
        "    (\"I love the new features of this app!\", 'positive'),\n",
        "    (\"The customer support is excellent.\", 'positive'),\n",
        "    (\"This product is a disappointment.\", 'negative'),\n",
        "    (\"I can't recommend this service to anyone.\", 'negative'),\n",
        "]\n",
        "\n",
        "classifer=NaiveBayesClassifier(train_data)\n",
        "test_data=\"the product is not bad\"\n",
        "classification=classifier.classify(test_data)\n",
        "print(classification)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vtMFZvnZ68r1",
        "outputId": "d95d8bf0-7f68-492d-fa91-8bbd70b95b44"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Translation"
      ],
      "metadata": {
        "id": "SPNl3CnG9N37"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install googletrans==4.0.0-rc1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 929
        },
        "id": "obkcxEyi9n3I",
        "outputId": "bb5f2e62-a68d-441b-8b35-e2aa0c9ea825"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting googletrans==4.0.0-rc1\n",
            "  Downloading googletrans-4.0.0rc1.tar.gz (20 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting httpx==0.13.3 (from googletrans==4.0.0-rc1)\n",
            "  Downloading httpx-0.13.3-py3-none-any.whl (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.1/55.1 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2023.11.17)\n",
            "Collecting hstspreload (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading hstspreload-2024.1.5-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.3.0)\n",
            "Collecting chardet==3.* (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.4/133.4 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting idna==2.* (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rfc3986<2,>=1.3 (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
            "Collecting httpcore==0.9.* (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading httpcore-0.9.1-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.10,>=0.8 (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading h11-0.9.0-py2.py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h2==3.* (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading h2-3.2.0-py2.py3-none-any.whl (65 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.0/65.0 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting hyperframe<6,>=5.2.0 (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading hyperframe-5.2.0-py2.py3-none-any.whl (12 kB)\n",
            "Collecting hpack<4,>=3.0 (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading hpack-3.0.0-py2.py3-none-any.whl (38 kB)\n",
            "Building wheels for collected packages: googletrans\n",
            "  Building wheel for googletrans (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for googletrans: filename=googletrans-4.0.0rc1-py3-none-any.whl size=17396 sha256=2401f85e6a5467db69305d036672ac02abee4ebf9d3937d576e7d939f86e3737\n",
            "  Stored in directory: /root/.cache/pip/wheels/c0/59/9f/7372f0cf70160fe61b528532e1a7c8498c4becd6bcffb022de\n",
            "Successfully built googletrans\n",
            "Installing collected packages: rfc3986, hyperframe, hpack, h11, chardet, idna, hstspreload, h2, httpcore, httpx, googletrans\n",
            "  Attempting uninstall: chardet\n",
            "    Found existing installation: chardet 5.2.0\n",
            "    Uninstalling chardet-5.2.0:\n",
            "      Successfully uninstalled chardet-5.2.0\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.6\n",
            "    Uninstalling idna-3.6:\n",
            "      Successfully uninstalled idna-3.6\n",
            "Successfully installed chardet-3.0.4 googletrans-4.0.0rc1 h11-0.9.0 h2-3.2.0 hpack-3.0.0 hstspreload-2024.1.5 httpcore-0.9.1 httpx-0.13.3 hyperframe-5.2.0 idna-2.10 rfc3986-1.5.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "chardet",
                  "idna"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from googletrans import Translator\n",
        "translator = Translator()\n",
        "text_to_translate = \"Hello, how are you?\"\n",
        "translated_text = translator.translate(text_to_translate, dest='es').text\n",
        "print(\"Original Text:\", text_to_translate)\n",
        "print(\"Translated Text:\", translated_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "koiXtNTS7uxw",
        "outputId": "97892ff1-1fba-4de3-d14d-c0a4f91917b8"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Text: Hello, how are you?\n",
            "Translated Text: ¿Hola, cómo estás?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sentiment Analysis"
      ],
      "metadata": {
        "id": "kucNOmA7-PAd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob\n",
        "text = \"I hate using TextBlob! It's a fantastic library.\"\n",
        "blob = TextBlob(text)\n",
        "sentiment = blob.sentiment\n",
        "print(\"Sentiment Analysis:\")\n",
        "print(f\"Polarity: {sentiment.polarity}\")\n",
        "print(f\"Subjectivity: {sentiment.subjectivity}\")\n",
        "if sentiment.polarity > 0:\n",
        "    print(\"Overall sentiment: Positive\")\n",
        "elif sentiment.polarity < 0:\n",
        "    print(\"Overall sentiment: Negative\")\n",
        "else:\n",
        "    print(\"Overall sentiment: Neutral\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dOssdQhl9EPq",
        "outputId": "cc37d471-33fc-41c8-f138-bcc695eeb72e"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiment Analysis:\n",
            "Polarity: -0.3\n",
            "Subjectivity: 0.9\n",
            "Overall sentiment: Negative\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0-IXAKzP-vAZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}